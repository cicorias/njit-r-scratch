---
title: "Lab 8 - Shawn Cicoria"
author: "Shawn Cicoria"
date: "April 14 2020"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

## Setup
Download the winequality-red_binary.csv file from Canvas

## Classification
### Question 1 
- Use the first half of the training data (rows) to train a Logistic Regression model to make prediction for the independent variable “quality_bin”, and then
- Test on the second half of the training data

> Q: What is the classification error you obtain? 

> Q: What is the AUC of the testing? 

- Make a ROC curve of it.

### Question 2
- Conduct 5-fold cross-validation using the entire training data to estimate the classification error
> Q: Is it larger or smaller than the classification error you obtain in (1)? 

> Q: Which one will be closer to the true classification error of your classifier do you think?



#### Load data.

```{r}

library(readr)


data_file <- 'winequality-red_binary.csv'
getwd()

if(!file.exists(data_file)){
  setwd('./labs/lab8')
  getwd()
}


wine_red <- read_csv("./winequality-red_binary.csv", 
    col_types = cols(quality_bin = col_integer(),
                     row = col_skip()))


```


```{r}

par(mfrow=c(3,4))

for(i in 1:11) {
    hist(wine_red[[i]], main=names(wine_red)[i])
}


```


```{r}

par(mfrow=c(2,6))

for(i in 1:11) {
    boxplot(wine_red[[i]], main=names(wine_red)[i])
}

```


```{r}
library(corrplot)
# i add back in quality_bin to see what features are 
# highly correlated to quality.
correlations <- cor(wine_red[,1:12])
corrplot(correlations, method="circle")

```

```{r}
##pairs(wine_red, col=wine_red$quality_bin)
library(dplyr)

#wine_red$split <- sample(c(FALSE, TRUE), nrow(wine_red), replace = TRUE, prob = c(0.5, 0.5))

#train_data_ng <- wine_red %>% filter(split == TRUE) %>% select(1:12)
#test_data_ng <- wine_red %>% filter(split == FALSE) %>% select(1:12)

#length(wine_red$split[wine_red$split == TRUE])

```

```{r}

# unfortunately, the prior approach doesn't give me a good 50/50 split.

train_data <-  wine_red[1:800, ]
test_data <- wine_red[801:1599,]


```




```{r}



trained_model <- glm(formula = train_data$quality_bin ~ 
                    train_data$fixed.acidity +
                    train_data$volatile.acidity +
                    train_data$citric.acid +
                    train_data$residual.sugar +
                    train_data$chlorides +
                    train_data$free.sulfur.dioxide +
                    train_data$total.sulfur.dioxide +
                    train_data$density +
                    train_data$pH +
                    train_data$sulphates +
                    train_data$alcohol, 
                    data = train_data, 
                    family = binomial)


summary(trained_model)

```

```{r}

# this is cleaner and simpler too.
trained_model <- glm(formula = train_data$quality_bin ~ .,
                    data = train_data, family = binomial)
summary(trained_model)
```



```{r}
p_out_prob <- predict(trained_model, test_data[,-12], type = "response")

summary(p_out)
```

```{r}

# OK, so I don't need to "drop" the response or prediction column fron the test data...
# this is a vector of prediction probability
p_out_prob <- predict(trained_model, test_data, type = "response")

summary(p_out)
```


```{r}
p_out <- data.frame(prediction = if_else(p_out_prob < 0.5, 0, 1), quality_bin = test_data[,12])


p_out$correct <- p_out$prediction == p_out$quality_bin
head(p_out)
```

```{r}
# classification error:

cat('classification error: ', 1 - sum(p_out$correct) / (sum(p_out$correct) + sum(!p_out$correct) ))

cat('\nclassification error: ', mean(p_out$prediction != p_out$quality_bin))

cat('\n\nConfusion matrix....\n')

table(p_out$prediction, test_data$quality_bin)
```

```{r}
pred_2 <- predict(trained_model, test_data, type = "response")
pred_3 <- prediction(pred_2, test_data$quality_bin)

roc_perf <- performance(pred_3, measure = "tpr", x.measure = "fpr")
plot(roc_perf, colorize = TRUE)
abline(a=0, b= 1)

auc_perf <- performance(pred_3, measure = "auc")

#print("AUC: ", auc_perf@y.values)

```

