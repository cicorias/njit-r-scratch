---
title: "Lab 8 - Shawn Cicoria"
date: "April 14 2020"
author: "Shawn Cicoria"
output: html_notebook
---

## Setup
Download the winequality-red_binary.csv file from Canvas

## Classification
### Question 1 
- Use the first half of the training data (rows) to train a Logistic Regression model to make prediction for the independent variable “quality_bin”, and then
- Test on the second half of the training data

> Q: What is the classification error you obtain? 

> Q: What is the AUC of the testing? 

- Make a ROC curve of it.

### Question 2
- Conduct 5-fold cross-validation using the entire training data to estimate the classification error
> Q: Is it larger or smaller than the classification error you obtain in (1)? 

> Q: Which one will be closer to the true classification error of your classifier do you think?



```{r}
library(readr)
getwd()
#setwd('./labs/lab8')
#wine_red <- read_csv("./winequality-red_binary.csv", 
#    col_types = cols(X1 = col_skip(), quality_bin = col_factor(levels = c("0", "1"))))


wine_red <- read_csv("./winequality-red_binary.csv", 
    col_types = cols(quality_bin = col_integer()))


```


```{r}

par(mfrow=c(3,4))

for(i in 2:12) {
    hist(wine_red[[i]], main=names(wine_red)[i])
}

```

```{r}
par(mfrow=c(2,6))

for(i in 2:12) {
    boxplot(wine_red[[i]], main=names(wine_red)[i])
}
```


```{r}
library(corrplot)
# i add back in quality_bin to see what features are 
# highly correlated to quality.
correlations <- cor(wine_red[,2:13])
corrplot(correlations, method="circle")

```

```{r}
##pairs(wine_red, col=wine_red$quality_bin)
library(dplyr)

wine_red$split <- sample(c(FALSE, TRUE), nrow(wine_red), replace = TRUE, prob = c(0.5, 0.5))

train_data <- wine_red %>% filter(split == TRUE) %>% select(2:13)
test_data <- wine_red %>% filter(split == FALSE) %>% select(2:13)

length(wine_red$split[wine_red$split == TRUE])

```

```{r}

train_data <-  wine_red[1:800, ]
test_data <- wine_red[801:1599,]


```




```{r}



trained_model <- glm(train_data$quality_bin ~ 
                    train_data$fixed.acidity +
                    train_data$volatile.acidity +
                    train_data$citric.acid +
                    train_data$residual.sugar +
                    train_data$chlorides +
                    train_data$free.sulfur.dioxide +
                    train_data$total.sulfur.dioxide +
                    train_data$density +
                    train_data$pH +
                    train_data$sulphates +
                    train_data$alcohol, 
                    data = train_data, family = binomial)


summary(trained_model)

```

```{r}
trained_model <- glm(formula = train_data$quality_bin ~ .,
                    data = train_data, family = binomial)


summary(trained_model)
```



```{r}
p_out <- predict(trained_model, test_data, type = "response")

summary(p_out)
```
```{r}
 predict(trained_model, test_data)
```

